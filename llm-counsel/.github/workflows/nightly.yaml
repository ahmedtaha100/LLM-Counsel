name: Nightly

on:
  schedule:
    - cron: "0 3 * * *"
  workflow_dispatch:

jobs:
  integration-tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - name: Install dependencies
        run: |
          pip install -r requirements.txt -r requirements-dev.txt
      - name: Run mocked integration tests
        run: |
          pytest tests/integration -v --ignore=tests/integration/test_model_calls.py

  live-integration:
    runs-on: ubuntu-latest
    environment: live-testing
    needs: integration-tests
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - name: Install dependencies
        run: |
          pip install -r requirements.txt -r requirements-dev.txt
      - name: Run live integration tests
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          TOGETHER_API_KEY: ${{ secrets.TOGETHER_API_KEY }}
          LIVE_TESTS: "1"
        run: |
          pytest tests/integration/test_model_calls.py -v --tb=short 2>&1 | tee live-test-results.txt
      - name: Upload live test results
        uses: actions/upload-artifact@v4
        with:
          name: live-test-results
          path: live-test-results.txt

  benchmarks:
    runs-on: ubuntu-latest
    environment: live-testing
    needs: live-integration
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - name: Install dependencies
        run: |
          pip install -r requirements.txt -r requirements-dev.txt
      - name: Run benchmarks
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          TOGETHER_API_KEY: ${{ secrets.TOGETHER_API_KEY }}
        run: |
          python scripts/run_benchmark.py --output benchmark-results.json
      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: benchmark-results.json

  notify:
    runs-on: ubuntu-latest
    needs: [integration-tests, live-integration, benchmarks]
    if: always()
    steps:
      - name: Download benchmark results
        if: ${{ needs.benchmarks.result == 'success' }}
        uses: actions/download-artifact@v4
        with:
          name: benchmark-results
          path: .
        continue-on-error: true

      - name: Create summary
        run: |
          echo "## Nightly Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Job | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-----|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Integration Tests | ${{ needs.integration-tests.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Live Integration | ${{ needs.live-integration.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Benchmarks | ${{ needs.benchmarks.result }} |" >> $GITHUB_STEP_SUMMARY

          if [ -f benchmark-results.json ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### Benchmark Results" >> $GITHUB_STEP_SUMMARY
            echo '```json' >> $GITHUB_STEP_SUMMARY
            cat benchmark-results.json >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          fi

      - name: Notify on failure
        if: ${{ needs.integration-tests.result == 'failure' || needs.live-integration.result == 'failure' || needs.benchmarks.result == 'failure' }}
        env:
          SLACK_WEBHOOK: ${{ secrets.SLACK_WEBHOOK }}
        run: |
          if [ -n "$SLACK_WEBHOOK" ]; then
            curl -X POST -H 'Content-type: application/json' \
              --data "{\"text\":\"Nightly tests failed for LLM-Counsel\nIntegration: ${{ needs.integration-tests.result }}\nLive: ${{ needs.live-integration.result }}\nBenchmarks: ${{ needs.benchmarks.result }}\"}" \
              "$SLACK_WEBHOOK"
          fi
